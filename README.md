# Project Name

**Multi-Modal Python Project**

## Overview

This project is a multi-modal model that accepts audio, images, and text as inputs, generating corresponding audio, images, and text outputs.

## Features

- **Input Modalities:** Audio, Images, Text
- **Output Modalities:** Audio, Images, Text

## Getting Started

### Prerequisites

- Python 3.x
- Dependencies listed in `requirements.txt`

### Installation

```bash
git clone https://github.com/Kind-Unes/Multi-Model-V1.git
cd 'MultiMODEL Template'
pip install -r requirements.txt
```
# Usage

python model.py

## Credits

### TXT2IMG Models
s
- [OpenDalleV1.1](https://huggingface.co/dataautogpt3/OpenDalleV1.1)
- [SSD-1B](https://huggingface.co/segmind/SSD-1B).
- [SSD-1B-Anime](https://huggingface.co/furusu/SSD-1B-anime)

### Text Generation Model

- [GOOGLE-GEMINI](https://deepmind.google/technologies/gemini/#introduction)

### IMG2TXT Model

- [BLIP_IMAGE_CAPTIONING_LARGE](https://huggingface.co/Salesforce/blip-image-captioning-large)

### TTS Model

- [FACEBOOK_MMS_TTS_ENG](https://huggingface.co/models/facebook/mms-tts-eng)

### STT Model

- [OPENAI_WHISPER_LARGE_V2](https://huggingface.co/openai/whisper-large-v2)


### Websites
- [Base64-Image-Viewer](https://base64-viewer.onrender.com).
- [Base64-Audio-Reader](https://base64.guru/converter/decode/audio).


